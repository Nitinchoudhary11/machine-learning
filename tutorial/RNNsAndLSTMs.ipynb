{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RNNsAndLSTMs.ipynb","provenance":[],"authorship_tag":"ABX9TyO9TtrPbG+DYVqLCgWJyPy6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"3lfUMFlfB_j2","executionInfo":{"status":"ok","timestamp":1632974294046,"user_tz":-330,"elapsed":349,"user":{"displayName":"Indrakumar Mhaski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAAh_TISGb7Ja14PgENiNwdvPygUS7ICe--ARd=s64","userId":"01598075014336494598"}}},"source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","import numpy as np\n","\n","# Parameters for the model and dataset.\n","TRAINING_SIZE = 50000\n","DIGITS = 3\n","REVERSE = False\n","\n","# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n","# int is DIGITS.\n","MAXLEN = DIGITS + 1 + DIGITS"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qcsh0rOkCMJU","executionInfo":{"status":"ok","timestamp":1632975685149,"user_tz":-330,"elapsed":7426,"user":{"displayName":"Indrakumar Mhaski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAAh_TISGb7Ja14PgENiNwdvPygUS7ICe--ARd=s64","userId":"01598075014336494598"}},"outputId":"68aa2784-8c9a-4321-db16-1cb76018e99c"},"source":["class CharacterTable:\n","    \"\"\"Given a set of characters:\n","    + Encode them to a one-hot integer representation\n","    + Decode the one-hot or integer representation to their character output\n","    + Decode a vector of probabilities to their character output\n","    \"\"\"\n","\n","    def __init__(self, chars):\n","        \"\"\"Initialize character table.\n","        # Arguments\n","            chars: Characters that can appear in the input.\n","        \"\"\"\n","        self.chars = sorted(set(chars))\n","        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n","        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n","        print(self.char_indices,self.indices_char)\n","\n","    def encode(self, C, num_rows):\n","        \"\"\"One-hot encode given string C.\n","        # Arguments\n","            C: string, to be encoded.\n","            num_rows: Number of rows in the returned one-hot encoding. This is\n","                used to keep the # of rows for each data the same.\n","        \"\"\"\n","        x = np.zeros((num_rows, len(self.chars)))\n","        for i, c in enumerate(C):\n","            x[i, self.char_indices[c]] = 1\n","        return x\n","\n","    def decode(self, x, calc_argmax=True):\n","        \"\"\"Decode the given vector or 2D array to their character output.\n","        # Arguments\n","            x: A vector or a 2D array of probabilities or one-hot representations;\n","                or a vector of character indices (used with `calc_argmax=False`).\n","            calc_argmax: Whether to find the character index with maximum\n","                probability, defaults to `True`.\n","        \"\"\"\n","        if calc_argmax:\n","            x = x.argmax(axis=-1)\n","        return \"\".join(self.indices_char[x] for x in x)\n","\n","\n","# All the numbers, plus sign and space for padding.\n","chars = \"0123456789+ \"\n","ctable = CharacterTable(chars)\n","\n","questions = []\n","expected = []\n","seen = set()\n","print(\"Generating data...\")\n","while len(questions) < TRAINING_SIZE:\n","    f = lambda: int(\n","        \"\".join(np.random.choice(list(\"0123456789\")) for i in range(np.random.randint(1, DIGITS + 1)))\n","    )\n","    a, b = f(), f()\n","    # Skip any addition questions we've already seen\n","    # Also skip any such that x+Y == Y+x (hence the sorting).\n","    key = tuple(sorted((a, b)))\n","    if key in seen:\n","        continue\n","    seen.add(key)\n","    # Pad the data with spaces such that it is always MAXLEN.\n","    q = \"{}+{}\".format(a, b)\n","    query = q + \" \" * (MAXLEN - len(q))\n","    ans = str(a + b)\n","    # Answers can be of maximum size DIGITS + 1.\n","    ans += \" \" * (DIGITS + 1 - len(ans))\n","    if REVERSE:\n","        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n","        # space used for padding.)\n","        query = query[::-1]\n","    questions.append(query)\n","    expected.append(ans)\n","print(\"Total questions:\", len(questions))\n","print(questions[0],expected[0])"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["{' ': 0, '+': 1, '0': 2, '1': 3, '2': 4, '3': 5, '4': 6, '5': 7, '6': 8, '7': 9, '8': 10, '9': 11} {0: ' ', 1: '+', 2: '0', 3: '1', 4: '2', 5: '3', 6: '4', 7: '5', 8: '6', 9: '7', 10: '8', 11: '9'}\n","Generating data...\n","Total questions: 50000\n","45+9    54  \n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-zSceumgCXuF","executionInfo":{"status":"ok","timestamp":1632975187346,"user_tz":-330,"elapsed":388,"user":{"displayName":"Indrakumar Mhaski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAAh_TISGb7Ja14PgENiNwdvPygUS7ICe--ARd=s64","userId":"01598075014336494598"}},"outputId":"b6d3a4e2-47ad-4311-fc18-62b87a68e85a"},"source":["print(\"Vectorization...\")\n","x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n","y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n","for i, sentence in enumerate(questions):\n","    x[i] = ctable.encode(sentence, MAXLEN)\n","for i, sentence in enumerate(expected):\n","    y[i] = ctable.encode(sentence, DIGITS + 1)\n","\n","# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n","# digits.\n","indices = np.arange(len(y))\n","np.random.shuffle(indices)\n","x = x[indices]\n","y = y[indices]\n","\n","# Explicitly set apart 10% for validation data that we never train over.\n","split_at = len(x) - len(x) // 10\n","(x_train, x_val) = x[:split_at], x[split_at:]\n","(y_train, y_val) = y[:split_at], y[split_at:]\n","\n","print(\"Training Data:\")\n","print(x_train.shape)\n","print(y_train.shape)\n","\n","print(\"Validation Data:\")\n","print(x_val.shape)\n","print(y_val.shape)\n","\n","print(x_train[0], ctable.decode(x_train[0]))\n","print(y_train[0], ctable.decode(y_train[0]))"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Vectorization...\n","Training Data:\n","(45000, 7, 12)\n","(45000, 4, 12)\n","Validation Data:\n","(5000, 7, 12)\n","(5000, 4, 12)\n","[[False False False False False False False  True False False False False]\n"," [False False False False  True False False False False False False False]\n"," [False  True False False False False False False False False False False]\n"," [False False False False False False False False False  True False False]\n"," [False False False False False False False False False  True False False]\n"," [ True False False False False False False False False False False False]\n"," [ True False False False False False False False False False False False]] 52+77  \n","[[False False False  True False False False False False False False False]\n"," [False False False False  True False False False False False False False]\n"," [False False False False False False False False False False False  True]\n"," [ True False False False False False False False False False False False]] 129 \n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CrvXEtB0HjGX","executionInfo":{"status":"ok","timestamp":1632974447655,"user_tz":-330,"elapsed":7176,"user":{"displayName":"Indrakumar Mhaski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAAh_TISGb7Ja14PgENiNwdvPygUS7ICe--ARd=s64","userId":"01598075014336494598"}},"outputId":"838fbc4d-dba0-4cd9-9a5e-0bbc17b14f4b"},"source":["print(\"Build model...\")\n","num_layers = 1  # Try to add more LSTM layers!\n","\n","model = keras.Sequential()\n","# \"Encode\" the input sequence using a LSTM, producing an output of size 128.\n","# Note: In a situation where your input sequences have a variable length,\n","# use input_shape=(None, num_feature).\n","model.add(layers.LSTM(128, input_shape=(MAXLEN, len(chars))))\n","# As the decoder RNN's input, repeatedly provide with the last output of\n","# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n","# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n","model.add(layers.RepeatVector(DIGITS + 1))\n","# The decoder RNN could be multiple layers stacked or a single layer.\n","for _ in range(num_layers):\n","    # By setting return_sequences to True, return not only the last output but\n","    # all the outputs so far in the form of (num_samples, timesteps,\n","    # output_dim). This is necessary as TimeDistributed in the below expects\n","    # the first dimension to be the timesteps.\n","    model.add(layers.LSTM(128, return_sequences=True))\n","\n","# Apply a dense layer to the every temporal slice of an input. For each of step\n","# of the output sequence, decide which character should be chosen.\n","model.add(layers.Dense(len(chars), activation=\"softmax\"))\n","model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","model.summary()"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Build model...\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm (LSTM)                  (None, 128)               72192     \n","_________________________________________________________________\n","repeat_vector (RepeatVector) (None, 4, 128)            0         \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 4, 128)            131584    \n","_________________________________________________________________\n","dense (Dense)                (None, 4, 12)             1548      \n","=================================================================\n","Total params: 205,324\n","Trainable params: 205,324\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FnyF1jDeHnfj","executionInfo":{"status":"ok","timestamp":1632975043902,"user_tz":-330,"elapsed":518650,"user":{"displayName":"Indrakumar Mhaski","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhAAh_TISGb7Ja14PgENiNwdvPygUS7ICe--ARd=s64","userId":"01598075014336494598"}},"outputId":"6f1a4e61-cb3d-4e68-d1db-7bfb505b9a84"},"source":["epochs = 30\n","batch_size = 32\n","\n","\n","# Train the model each generation and show predictions against the validation\n","# dataset.\n","for epoch in range(1, epochs):\n","    print()\n","    print(\"Iteration\", epoch)\n","    model.fit(\n","        x_train,\n","        y_train,\n","        batch_size=batch_size,\n","        epochs=1,\n","        validation_data=(x_val, y_val),\n","    )\n","    # Select 10 samples from the validation set at random so we can visualize\n","    # errors.\n","    for i in range(10):\n","        ind = np.random.randint(0, len(x_val))\n","        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n","        preds = np.argmax(model.predict(rowx), axis=-1)\n","        q = ctable.decode(rowx[0])\n","        correct = ctable.decode(rowy[0])\n","        guess = ctable.decode(preds[0], calc_argmax=False)\n","        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n","        print(\"T\", correct, end=\" \")\n","        if correct == guess:\n","            print(\"☑ \" + guess)\n","        else:\n","            print(\"☒ \" + guess)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Iteration 1\n","1407/1407 [==============================] - 23s 10ms/step - loss: 1.7615 - accuracy: 0.3549 - val_loss: 1.5367 - val_accuracy: 0.4236\n","Q 768+9   T 777  ☒ 765 \n","Q 996+72  T 1068 ☒ 100 \n","Q 1+231   T 232  ☒ 22  \n","Q 930+32  T 962  ☒ 900 \n","Q 249+70  T 319  ☒ 350 \n","Q 6+726   T 732  ☒ 66  \n","Q 76+951  T 1027 ☒ 902 \n","Q 87+607  T 694  ☒ 732 \n","Q 77+58   T 135  ☒ 755 \n","Q 73+10   T 83   ☒ 10  \n","\n","Iteration 2\n","1407/1407 [==============================] - 13s 9ms/step - loss: 1.3643 - accuracy: 0.4851 - val_loss: 1.2566 - val_accuracy: 0.5242\n","Q 877+4   T 881  ☒ 885 \n","Q 507+3   T 510  ☒ 587 \n","Q 313+87  T 400  ☒ 307 \n","Q 505+23  T 528  ☒ 557 \n","Q 116+868 T 984  ☒ 1037\n","Q 81+601  T 682  ☒ 785 \n","Q 32+73   T 105  ☒ 107 \n","Q 94+649  T 743  ☑ 743 \n","Q 839+49  T 888  ☒ 867 \n","Q 904+62  T 966  ☒ 963 \n","\n","Iteration 3\n","1407/1407 [==============================] - 13s 10ms/step - loss: 1.1467 - accuracy: 0.5662 - val_loss: 1.0776 - val_accuracy: 0.5877\n","Q 828+52  T 880  ☒ 999 \n","Q 733+418 T 1151 ☒ 1177\n","Q 492+56  T 548  ☒ 533 \n","Q 48+356  T 404  ☒ 403 \n","Q 774+34  T 808  ☒ 807 \n","Q 603+48  T 651  ☒ 653 \n","Q 91+58   T 149  ☒ 153 \n","Q 46+307  T 353  ☒ 365 \n","Q 401+14  T 415  ☒ 411 \n","Q 54+38   T 92   ☒ 90  \n","\n","Iteration 4\n","1407/1407 [==============================] - 13s 9ms/step - loss: 0.9946 - accuracy: 0.6229 - val_loss: 0.9678 - val_accuracy: 0.6280\n","Q 60+777  T 837  ☒ 842 \n","Q 882+28  T 910  ☒ 900 \n","Q 67+605  T 672  ☒ 679 \n","Q 566+65  T 631  ☒ 634 \n","Q 117+47  T 164  ☒ 167 \n","Q 222+584 T 806  ☒ 800 \n","Q 738+997 T 1735 ☒ 1736\n","Q 107+45  T 152  ☒ 147 \n","Q 36+43   T 79   ☒ 86  \n","Q 376+27  T 403  ☒ 393 \n","\n","Iteration 5\n","1407/1407 [==============================] - 13s 10ms/step - loss: 0.9080 - accuracy: 0.6574 - val_loss: 0.8918 - val_accuracy: 0.6593\n","Q 581+526 T 1107 ☒ 1032\n","Q 18+98   T 116  ☒ 117 \n","Q 25+215  T 240  ☒ 244 \n","Q 253+460 T 713  ☒ 691 \n","Q 594+2   T 596  ☒ 594 \n","Q 61+517  T 578  ☒ 579 \n","Q 537+314 T 851  ☒ 859 \n","Q 5+771   T 776  ☑ 776 \n","Q 917+83  T 1000 ☒ 100 \n","Q 875+85  T 960  ☒ 951 \n","\n","Iteration 6\n","1407/1407 [==============================] - 13s 10ms/step - loss: 0.8370 - accuracy: 0.6833 - val_loss: 0.8368 - val_accuracy: 0.6758\n","Q 9+854   T 863  ☑ 863 \n","Q 85+336  T 421  ☒ 411 \n","Q 974+88  T 1062 ☒ 1061\n","Q 543+806 T 1349 ☒ 1353\n","Q 537+65  T 602  ☒ 501 \n","Q 20+5    T 25   ☒ 26  \n","Q 341+69  T 410  ☒ 400 \n","Q 1+491   T 492  ☒ 489 \n","Q 99+461  T 560  ☒ 554 \n","Q 531+8   T 539  ☒ 549 \n","\n","Iteration 7\n","1407/1407 [==============================] - 13s 10ms/step - loss: 0.7690 - accuracy: 0.7107 - val_loss: 0.7351 - val_accuracy: 0.7192\n","Q 570+1   T 571  ☑ 571 \n","Q 957+206 T 1163 ☒ 1156\n","Q 187+117 T 304  ☒ 398 \n","Q 72+678  T 750  ☒ 753 \n","Q 14+547  T 561  ☒ 568 \n","Q 6+40    T 46   ☒ 45  \n","Q 666+206 T 872  ☒ 875 \n","Q 84+911  T 995  ☒ 993 \n","Q 37+94   T 131  ☒ 132 \n","Q 95+905  T 1000 ☒ 998 \n","\n","Iteration 8\n","1407/1407 [==============================] - 13s 10ms/step - loss: 0.6685 - accuracy: 0.7478 - val_loss: 0.5969 - val_accuracy: 0.7682\n","Q 8+978   T 986  ☑ 986 \n","Q 206+155 T 361  ☒ 259 \n","Q 88+251  T 339  ☒ 337 \n","Q 8+627   T 635  ☑ 635 \n","Q 950+28  T 978  ☒ 979 \n","Q 0+225   T 225  ☒ 223 \n","Q 707+910 T 1617 ☑ 1617\n","Q 444+24  T 468  ☒ 467 \n","Q 417+192 T 609  ☒ 600 \n","Q 355+54  T 409  ☒ 400 \n","\n","Iteration 9\n","1407/1407 [==============================] - 14s 10ms/step - loss: 0.5026 - accuracy: 0.8150 - val_loss: 0.4122 - val_accuracy: 0.8580\n","Q 709+560 T 1269 ☒ 1267\n","Q 5+859   T 864  ☑ 864 \n","Q 457+73  T 530  ☑ 530 \n","Q 6+186   T 192  ☒ 182 \n","Q 73+50   T 123  ☑ 123 \n","Q 305+19  T 324  ☑ 324 \n","Q 984+55  T 1039 ☒ 1049\n","Q 41+759  T 800  ☑ 800 \n","Q 738+644 T 1382 ☒ 1383\n","Q 10+915  T 925  ☒ 926 \n","\n","Iteration 10\n","1407/1407 [==============================] - 14s 10ms/step - loss: 0.3469 - accuracy: 0.8839 - val_loss: 0.3021 - val_accuracy: 0.9010\n","Q 165+744 T 909  ☑ 909 \n","Q 55+28   T 83   ☑ 83  \n","Q 25+213  T 238  ☑ 238 \n","Q 71+912  T 983  ☑ 983 \n","Q 816+97  T 913  ☑ 913 \n","Q 605+311 T 916  ☑ 916 \n","Q 74+427  T 501  ☒ 491 \n","Q 81+10   T 91   ☒ 90  \n","Q 465+907 T 1372 ☒ 1373\n","Q 43+120  T 163  ☑ 163 \n","\n","Iteration 11\n","1407/1407 [==============================] - 14s 10ms/step - loss: 0.2442 - accuracy: 0.9262 - val_loss: 0.2059 - val_accuracy: 0.9408\n","Q 26+97   T 123  ☑ 123 \n","Q 652+12  T 664  ☒ 654 \n","Q 72+439  T 511  ☑ 511 \n","Q 385+435 T 820  ☒ 810 \n","Q 84+145  T 229  ☑ 229 \n","Q 957+104 T 1061 ☒ 1051\n","Q 62+93   T 155  ☑ 155 \n","Q 77+632  T 709  ☑ 709 \n","Q 757+58  T 815  ☑ 815 \n","Q 39+11   T 50   ☒ 40  \n","\n","Iteration 12\n","1407/1407 [==============================] - 14s 10ms/step - loss: 0.1784 - accuracy: 0.9501 - val_loss: 0.1510 - val_accuracy: 0.9586\n","Q 72+485  T 557  ☑ 557 \n","Q 85+299  T 384  ☑ 384 \n","Q 420+4   T 424  ☑ 424 \n","Q 648+40  T 688  ☑ 688 \n","Q 742+7   T 749  ☑ 749 \n","Q 936+950 T 1886 ☑ 1886\n","Q 98+6    T 104  ☑ 104 \n","Q 83+230  T 313  ☑ 313 \n","Q 64+881  T 945  ☑ 945 \n","Q 112+56  T 168  ☑ 168 \n","\n","Iteration 13\n","1407/1407 [==============================] - 14s 10ms/step - loss: 0.1341 - accuracy: 0.9637 - val_loss: 0.1219 - val_accuracy: 0.9664\n","Q 4+555   T 559  ☑ 559 \n","Q 98+929  T 1027 ☑ 1027\n","Q 733+418 T 1151 ☒ 1141\n","Q 798+470 T 1268 ☑ 1268\n","Q 1+895   T 896  ☑ 896 \n","Q 784+98  T 882  ☑ 882 \n","Q 616+27  T 643  ☑ 643 \n","Q 71+642  T 713  ☑ 713 \n","Q 1+985   T 986  ☑ 986 \n","Q 352+932 T 1284 ☑ 1284\n","\n","Iteration 14\n","1407/1407 [==============================] - 14s 10ms/step - loss: 0.1028 - accuracy: 0.9727 - val_loss: 0.0982 - val_accuracy: 0.9700\n","Q 57+669  T 726  ☑ 726 \n","Q 35+155  T 190  ☑ 190 \n","Q 311+64  T 375  ☑ 375 \n","Q 114+14  T 128  ☑ 128 \n","Q 275+46  T 321  ☑ 321 \n","Q 5+331   T 336  ☑ 336 \n","Q 44+141  T 185  ☑ 185 \n","Q 390+18  T 408  ☑ 408 \n","Q 92+608  T 700  ☑ 700 \n","Q 400+576 T 976  ☑ 976 \n","\n","Iteration 15\n","1407/1407 [==============================] - 13s 10ms/step - loss: 0.0931 - accuracy: 0.9734 - val_loss: 0.0847 - val_accuracy: 0.9761\n","Q 135+17  T 152  ☑ 152 \n","Q 77+415  T 492  ☒ 592 \n","Q 395+942 T 1337 ☑ 1337\n","Q 711+245 T 956  ☑ 956 \n","Q 563+94  T 657  ☑ 657 \n","Q 36+63   T 99   ☑ 99  \n","Q 74+232  T 306  ☑ 306 \n","Q 3+304   T 307  ☑ 307 \n","Q 278+90  T 368  ☑ 368 \n","Q 877+67  T 944  ☑ 944 \n","\n","Iteration 16\n","1407/1407 [==============================] - 14s 10ms/step - loss: 0.0692 - accuracy: 0.9814 - val_loss: 0.0614 - val_accuracy: 0.9828\n","Q 19+529  T 548  ☑ 548 \n","Q 78+16   T 94   ☑ 94  \n","Q 801+64  T 865  ☑ 865 \n","Q 6+935   T 941  ☑ 941 \n","Q 67+925  T 992  ☑ 992 \n","Q 107+716 T 823  ☒ 822 \n","Q 797+54  T 851  ☑ 851 \n","Q 764+405 T 1169 ☑ 1169\n","Q 327+642 T 969  ☑ 969 \n","Q 570+357 T 927  ☑ 927 \n","\n","Iteration 17\n","1407/1407 [==============================] - 14s 10ms/step - loss: 0.0600 - accuracy: 0.9828 - val_loss: 0.0697 - val_accuracy: 0.9783\n","Q 949+535 T 1484 ☒ 1483\n","Q 4+516   T 520  ☑ 520 \n","Q 57+192  T 249  ☒ 259 \n","Q 98+929  T 1027 ☑ 1027\n","Q 689+874 T 1563 ☑ 1563\n","Q 182+606 T 788  ☑ 788 \n","Q 188+99  T 287  ☑ 287 \n","Q 253+9   T 262  ☑ 262 \n","Q 969+368 T 1337 ☑ 1337\n","Q 915+3   T 918  ☑ 918 \n","\n","Iteration 18\n","1407/1407 [==============================] - 14s 10ms/step - loss: 0.0617 - accuracy: 0.9826 - val_loss: 0.1286 - val_accuracy: 0.9510\n","Q 57+192  T 249  ☑ 249 \n","Q 66+338  T 404  ☑ 404 \n","Q 677+5   T 682  ☑ 682 \n","Q 79+649  T 728  ☑ 728 \n","Q 186+35  T 221  ☑ 221 \n","Q 350+55  T 405  ☑ 405 \n","Q 547+33  T 580  ☑ 580 \n","Q 983+915 T 1898 ☒ 1908\n","Q 785+45  T 830  ☑ 830 \n","Q 43+13   T 56   ☑ 56  \n","\n","Iteration 19\n","1407/1407 [==============================] - 14s 10ms/step - loss: 0.0474 - accuracy: 0.9864 - val_loss: 0.0488 - val_accuracy: 0.9854\n","Q 409+21  T 430  ☒ 420 \n","Q 247+472 T 719  ☑ 719 \n","Q 0+226   T 226  ☑ 226 \n","Q 6+263   T 269  ☑ 269 \n","Q 230+78  T 308  ☑ 308 \n","Q 924+629 T 1553 ☒ 1562\n","Q 3+321   T 324  ☑ 324 \n","Q 839+593 T 1432 ☑ 1432\n","Q 13+492  T 505  ☑ 505 \n","Q 39+970  T 1009 ☑ 1009\n","\n","Iteration 20\n","1407/1407 [==============================] - 14s 10ms/step - loss: 0.0479 - accuracy: 0.9863 - val_loss: 0.0498 - val_accuracy: 0.9843\n","Q 41+296  T 337  ☑ 337 \n","Q 475+932 T 1407 ☑ 1407\n","Q 72+551  T 623  ☑ 623 \n","Q 458+70  T 528  ☑ 528 \n","Q 3+703   T 706  ☑ 706 \n","Q 91+448  T 539  ☑ 539 \n","Q 924+629 T 1553 ☒ 1563\n","Q 812+942 T 1754 ☒ 1744\n","Q 77+392  T 469  ☒ 479 \n","Q 3+257   T 260  ☑ 260 \n","\n","Iteration 21\n","1407/1407 [==============================] - 14s 10ms/step - loss: 0.0383 - accuracy: 0.9893 - val_loss: 0.0364 - val_accuracy: 0.9892\n","Q 63+19   T 82   ☑ 82  \n","Q 8+187   T 195  ☑ 195 \n","Q 357+15  T 372  ☑ 372 \n","Q 974+91  T 1065 ☑ 1065\n","Q 8+619   T 627  ☑ 627 \n","Q 78+23   T 101  ☑ 101 \n","Q 120+508 T 628  ☑ 628 \n","Q 15+858  T 873  ☑ 873 \n","Q 55+699  T 754  ☑ 754 \n","Q 307+5   T 312  ☑ 312 \n","\n","Iteration 22\n","1407/1407 [==============================] - 14s 10ms/step - loss: 0.0417 - accuracy: 0.9882 - val_loss: 0.0844 - val_accuracy: 0.9714\n","Q 622+674 T 1296 ☑ 1296\n","Q 48+356  T 404  ☑ 404 \n","Q 601+9   T 610  ☑ 610 \n","Q 326+65  T 391  ☑ 391 \n","Q 17+971  T 988  ☑ 988 \n","Q 138+54  T 192  ☑ 192 \n","Q 10+72   T 82   ☑ 82  \n","Q 345+69  T 414  ☑ 414 \n","Q 705+63  T 768  ☑ 768 \n","Q 143+169 T 312  ☑ 312 \n","\n","Iteration 23\n","1407/1407 [==============================] - 14s 10ms/step - loss: 0.0326 - accuracy: 0.9910 - val_loss: 0.1073 - val_accuracy: 0.9615\n","Q 41+296  T 337  ☑ 337 \n","Q 627+880 T 1507 ☑ 1507\n","Q 967+699 T 1666 ☑ 1666\n","Q 62+620  T 682  ☑ 682 \n","Q 73+54   T 127  ☑ 127 \n","Q 364+70  T 434  ☑ 434 \n","Q 443+69  T 512  ☑ 512 \n","Q 432+29  T 461  ☑ 461 \n","Q 642+793 T 1435 ☑ 1435\n","Q 2+608   T 610  ☑ 610 \n","\n","Iteration 24\n","1407/1407 [==============================] - 14s 10ms/step - loss: 0.0338 - accuracy: 0.9895 - val_loss: 0.0683 - val_accuracy: 0.9766\n","Q 176+25  T 201  ☑ 201 \n","Q 575+88  T 663  ☑ 663 \n","Q 67+767  T 834  ☑ 834 \n","Q 625+97  T 722  ☑ 722 \n","Q 286+80  T 366  ☑ 366 \n","Q 35+94   T 129  ☑ 129 \n","Q 572+828 T 1400 ☑ 1400\n","Q 753+17  T 770  ☑ 770 \n","Q 65+308  T 373  ☑ 373 \n","Q 13+806  T 819  ☑ 819 \n","\n","Iteration 25\n","1407/1407 [==============================] - 14s 10ms/step - loss: 0.0304 - accuracy: 0.9913 - val_loss: 0.0585 - val_accuracy: 0.9796\n","Q 523+2   T 525  ☑ 525 \n","Q 839+27  T 866  ☑ 866 \n","Q 862+69  T 931  ☑ 931 \n","Q 671+59  T 730  ☑ 730 \n","Q 18+11   T 29   ☒ 39  \n","Q 48+169  T 217  ☑ 217 \n","Q 208+71  T 279  ☑ 279 \n","Q 215+35  T 250  ☑ 250 \n","Q 4+431   T 435  ☑ 435 \n","Q 599+66  T 665  ☑ 665 \n","\n","Iteration 26\n","1407/1407 [==============================] - 14s 10ms/step - loss: 0.0291 - accuracy: 0.9915 - val_loss: 0.0517 - val_accuracy: 0.9829\n","Q 139+2   T 141  ☑ 141 \n","Q 58+88   T 146  ☑ 146 \n","Q 269+11  T 280  ☑ 280 \n","Q 871+92  T 963  ☑ 963 \n","Q 339+86  T 425  ☑ 425 \n","Q 524+889 T 1413 ☑ 1413\n","Q 907+233 T 1140 ☒ 1240\n","Q 95+542  T 637  ☑ 637 \n","Q 90+359  T 449  ☑ 449 \n","Q 800+7   T 807  ☑ 807 \n","\n","Iteration 27\n","1407/1407 [==============================] - 14s 10ms/step - loss: 0.0288 - accuracy: 0.9916 - val_loss: 0.0207 - val_accuracy: 0.9937\n","Q 668+94  T 762  ☑ 762 \n","Q 572+828 T 1400 ☑ 1400\n","Q 726+335 T 1061 ☑ 1061\n","Q 961+11  T 972  ☑ 972 \n","Q 42+380  T 422  ☑ 422 \n","Q 187+117 T 304  ☑ 304 \n","Q 575+88  T 663  ☑ 663 \n","Q 689+874 T 1563 ☑ 1563\n","Q 77+921  T 998  ☑ 998 \n","Q 42+173  T 215  ☑ 215 \n","\n","Iteration 28\n","1407/1407 [==============================] - 14s 10ms/step - loss: 0.0311 - accuracy: 0.9910 - val_loss: 0.0169 - val_accuracy: 0.9961\n","Q 82+660  T 742  ☑ 742 \n","Q 348+37  T 385  ☑ 385 \n","Q 840+489 T 1329 ☑ 1329\n","Q 960+142 T 1102 ☑ 1102\n","Q 47+780  T 827  ☑ 827 \n","Q 44+534  T 578  ☑ 578 \n","Q 588+6   T 594  ☑ 594 \n","Q 0+710   T 710  ☑ 710 \n","Q 368+2   T 370  ☒ 360 \n","Q 676+846 T 1522 ☑ 1522\n","\n","Iteration 29\n","1407/1407 [==============================] - 14s 10ms/step - loss: 0.0232 - accuracy: 0.9934 - val_loss: 0.0169 - val_accuracy: 0.9951\n","Q 678+529 T 1207 ☑ 1207\n","Q 704+881 T 1585 ☑ 1585\n","Q 113+95  T 208  ☑ 208 \n","Q 3+324   T 327  ☑ 327 \n","Q 222+956 T 1178 ☑ 1178\n","Q 983+915 T 1898 ☒ 1908\n","Q 1+28    T 29   ☑ 29  \n","Q 876+58  T 934  ☑ 934 \n","Q 581+9   T 590  ☑ 590 \n","Q 524+714 T 1238 ☑ 1238\n"]}]}]}