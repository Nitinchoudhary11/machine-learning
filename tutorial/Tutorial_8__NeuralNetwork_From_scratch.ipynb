{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial_8 _NeuralNetwork_From_scratch",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705
        },
        "id": "d_GQxtRb1iB9",
        "outputId": "021df9a6-45e7-4f10-c990-a306db14504b"
      },
      "source": [
        "# This tutorial is inspired and the code is borrowed from: \n",
        "# https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/\n",
        "\n",
        "from math import exp\n",
        "from random import seed\n",
        "from random import random\n",
        "\n",
        "# Initialize a network\n",
        "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
        "\tnetwork = list()\n",
        "\thidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
        "\tnetwork.append(hidden_layer)\n",
        "\toutput_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
        "\tnetwork.append(output_layer)\n",
        "\treturn network\n",
        "\n",
        "# Calculate neuron activation for an input\n",
        "def activate(weights, inputs):\n",
        "\tactivation = weights[-1]\n",
        "\tfor i in range(len(weights)-1):\n",
        "\t\tactivation += weights[i] * inputs[i]\n",
        "\treturn activation\n",
        "\n",
        "# Transfer neuron activation\n",
        "def transfer(activation):\n",
        "\treturn 1.0 / (1.0 + exp(-activation))\n",
        "\n",
        "# Forward propagate input to a network output\n",
        "def forward_propagate(network, row):\n",
        "\tinputs = row\n",
        "\tfor layer in network:\n",
        "\t\tnew_inputs = []\n",
        "\t\tfor neuron in layer:\n",
        "\t\t\tactivation = activate(neuron['weights'], inputs)\n",
        "\t\t\tneuron['output'] = transfer(activation)\n",
        "\t\t\tnew_inputs.append(neuron['output'])\n",
        "\t\tinputs = new_inputs\n",
        "\treturn inputs\n",
        "\n",
        "# Calculate the derivative of an neuron output\n",
        "def transfer_derivative(output):\n",
        "\treturn output * (1.0 - output)\n",
        "\n",
        "# Backpropagate error and store in neurons\n",
        "def backward_propagate_error(network, expected):\n",
        "\tfor i in reversed(range(len(network))):\n",
        "\t\tlayer = network[i]\n",
        "\t\terrors = list()\n",
        "\t\tif i != len(network)-1:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\terror = 0.0\n",
        "\t\t\t\tfor neuron in network[i + 1]:\n",
        "\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n",
        "\t\t\t\terrors.append(error)\n",
        "\t\telse:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\tneuron = layer[j]\n",
        "\t\t\t\terrors.append(expected[j] - neuron['output'])\n",
        "\t\tfor j in range(len(layer)):\n",
        "\t\t\tneuron = layer[j]\n",
        "\t\t\tneuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
        "\n",
        "# Update network weights with error\n",
        "def update_weights(network, row, l_rate):\n",
        "\tfor i in range(len(network)):\n",
        "\t\tinputs = row[:-1]\n",
        "\t\tif i != 0:\n",
        "\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n",
        "\t\tfor neuron in network[i]:\n",
        "\t\t\tfor j in range(len(inputs)):\n",
        "\t\t\t\tneuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n",
        "\t\t\tneuron['weights'][-1] += l_rate * neuron['delta']\n",
        "\n",
        "# Train a network for a fixed number of epochs\n",
        "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
        "\tfor epoch in range(n_epoch):\n",
        "\t\tsum_error = 0\n",
        "\t\tfor row in train:\n",
        "\t\t\toutputs = forward_propagate(network, row)\n",
        "\t\t\texpected = [0 for i in range(n_outputs)]\n",
        "\t\t\texpected[row[-1]] = 1\n",
        "\t\t\tsum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
        "\t\t\tbackward_propagate_error(network, expected)\n",
        "\t\t\tupdate_weights(network, row, l_rate)\n",
        "\t\tprint('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
        "\n",
        "\n",
        "# Test training backprop algorithm\n",
        "seed(1)\n",
        "dataset = [[2.7810836,2.550537003,0],\n",
        "\t[1.465489372,2.362125076,0],\n",
        "\t[3.396561688,4.400293529,0],\n",
        "\t[1.38807019,1.850220317,0],\n",
        "\t[3.06407232,3.005305973,0],\n",
        "\t[7.627531214,2.759262235,1],\n",
        "\t[5.332441248,2.088626775,1],\n",
        "\t[6.922596716,1.77106367,1],\n",
        "\t[8.675418651,-0.242068655,1],\n",
        "\t[7.673756466,3.508563011,1]]\n",
        "n_inputs = len(dataset[0]) - 1\n",
        "n_outputs = len(set([row[-1] for row in dataset]))\n",
        "network = initialize_network(n_inputs, 5, n_outputs)\n",
        "for layer in network:\n",
        "    \tprint(layer)\n",
        "train_network(network, dataset, 0.5, 20, n_outputs)\n",
        "for layer in network:\n",
        "\tprint(layer)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# =============================================== Ploating the Dataset===========================\n",
        "# scatter plot of blobs dataset\n",
        "from matplotlib import pyplot\n",
        "from numpy import where\n",
        "import numpy as np\n",
        "# scatter plot for each class value\n",
        "X= np.array(dataset)\n",
        "X, y= X[:,:-1], X[:,-1]\n",
        "\n",
        "# print(X,y)\n",
        "for class_value in range(2):\n",
        "\t# select indices of points with the class label\n",
        "\trow_ix = where(y == class_value)\n",
        "\t# scatter plot for points with a different color\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
        "# show plot\n",
        "pyplot.show()\n",
        "\n",
        "# =============================================== Ploating the Dataset =======================\n",
        "\n",
        "\n",
        "# Make a prediction with a network\n",
        "def predict(network, row):\n",
        "\toutputs = forward_propagate(network, row)\n",
        "\treturn outputs.index(max(outputs))\n",
        "\n",
        "\n",
        "print(predict(network, [7.70,1.01]))\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}, {'weights': [0.2550690257394217, 0.49543508709194095, 0.4494910647887381]}, {'weights': [0.651592972722763, 0.7887233511355132, 0.0938595867742349]}, {'weights': [0.02834747652200631, 0.8357651039198697, 0.43276706790505337]}, {'weights': [0.762280082457942, 0.0021060533511106927, 0.4453871940548014]}]\n",
            "[{'weights': [0.7215400323407826, 0.22876222127045265, 0.9452706955539223, 0.9014274576114836, 0.030589983033553536, 0.0254458609934608]}, {'weights': [0.5414124727934966, 0.9391491627785106, 0.38120423768821243, 0.21659939713061338, 0.4221165755827173, 0.029040787574867943]}]\n",
            ">epoch=0, lrate=0.500, error=8.138\n",
            ">epoch=1, lrate=0.500, error=6.111\n",
            ">epoch=2, lrate=0.500, error=4.643\n",
            ">epoch=3, lrate=0.500, error=4.348\n",
            ">epoch=4, lrate=0.500, error=3.989\n",
            ">epoch=5, lrate=0.500, error=3.579\n",
            ">epoch=6, lrate=0.500, error=3.142\n",
            ">epoch=7, lrate=0.500, error=2.680\n",
            ">epoch=8, lrate=0.500, error=2.224\n",
            ">epoch=9, lrate=0.500, error=1.840\n",
            ">epoch=10, lrate=0.500, error=1.539\n",
            ">epoch=11, lrate=0.500, error=1.300\n",
            ">epoch=12, lrate=0.500, error=1.108\n",
            ">epoch=13, lrate=0.500, error=0.952\n",
            ">epoch=14, lrate=0.500, error=0.826\n",
            ">epoch=15, lrate=0.500, error=0.722\n",
            ">epoch=16, lrate=0.500, error=0.636\n",
            ">epoch=17, lrate=0.500, error=0.565\n",
            ">epoch=18, lrate=0.500, error=0.506\n",
            ">epoch=19, lrate=0.500, error=0.456\n",
            "[{'weights': [-0.8385181387815848, 0.9257174774650863, 0.7623799205288111], 'output': 0.08898693070199849, 'delta': -0.002720302693300436}, {'weights': [0.47832923009431927, -0.4506001902594398, 0.13205182050893838], 'output': 0.8911009719162515, 'delta': 0.003314231435956368}, {'weights': [0.6657862278307307, 0.8296149718692944, 0.1116668078321355], 'output': 0.9997059650894071, 'delta': -3.710348932999531e-07}, {'weights': [-1.2962053841867047, 1.7519460885979419, 0.7445172859500724], 'output': 0.051561091903037815, 'delta': -0.0039720427075578026}, {'weights': [0.7463679163715649, -1.032899905253737, 0.07076435981548237], 'output': 0.8816474341118752, 'delta': 0.004601088305223243}]\n",
            "[{'weights': [1.0019664053669057, -0.6714121598038286, 0.2824515869621413, 2.193329809058453, -1.2712328884113355, -0.5745625746956659], 'output': 0.14467925912969903, 'delta': -0.017903649035211897}, {'weights': [-0.7775095591500943, 1.1202300895026098, 0.20732584338718182, -2.0921756897149435, 1.0802799458947958, -0.24077939426201606], 'output': 0.846081645576801, 'delta': 0.020044401668695894}]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    }
  ]
}